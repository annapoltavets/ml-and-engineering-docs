{
 "cells": [
  {
   "cell_type": "raw",
   "id": "b06e7130",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "Loaders are a core part of the LangChain framework, designed to ingest data from various sources—text, \n",
    "PDFs, web pages, databases, emails, and more—so you can process, chunk, embed, or use it in RAG or LLM pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c134cb60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76e61cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Text Loaders\n",
    "\n",
    "# Purpose: Load plain text files or strings.\n",
    "\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "loader = TextLoader('dataFolder/demo.txt')\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8702505e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'dataFolder/demo.txt'}, page_content='This is an example of using text file in langchain\\nlangchain is a powerful framework')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3a47e4a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'Skia/PDF m140 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'Untitled document', 'source': 'dataFolder/demo.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1'}, page_content=\"The  hippocampus is  a  major  component  of  the  brain of  humans and  many  other  vertebrates.  It  plays  important  roles  in  the  consolidation of  information  from  short-term  memory to  long-term  memory,  and  in  spatial  memory that  enables  navigation.  In  humans  and  other  primates,  the  hippocampus  is  located  in  the  archicortex,  one  of  the  three  regions  of  allocortex,  in  each  hemisphere.  The  hippocampus  is  a  structure  found  in  all  vertebrates.  In  Alzheimer's  disease (and  other  forms  of  dementia),  the  hippocampus  is  one  of  the  first  regions  of  the  brain  to  suffer  damage;  short-term  memory  loss and  disorientation are  included  among  the  early  symptoms.  Damage  to  the  hippocampus  can  also  result  from  oxygen  starvation,  encephalitis or  medial  temporal  lobe  epilepsy.  Since  different  neuronal  cell  types are  neatly  organized  into  layers  in  the  hippocampus,  it  has  frequently  been  used  as  a  model  system for  studying  neurophysiology.\")]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. PDF Loaders\n",
    "\n",
    "# Purpose: Extract text from PDF documents.\n",
    "# pip install pypdf\n",
    "\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader('dataFolder/demo.pdf')\n",
    "docs = loader.load()\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32613144",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://www.example.com', 'title': 'Example Domain', 'language': 'No language found.'}, page_content='\\n\\n\\nExample Domain\\n\\n\\n\\n\\n\\n\\n\\nExample Domain\\nThis domain is for use in illustrative examples in documents. You may use this\\n    domain in literature without prior coordination or asking for permission.\\nMore information...\\n\\n\\n\\n')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. Web Page Loaders\n",
    "\n",
    "# Purpose: Scrape or extract text/content from URLs.\n",
    "#pip install bs4\n",
    "\n",
    "\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "#headers = {\"User-Agent\": \"my-cool-app/1.0 (contact: youremail@example.com)\"}\n",
    "loader = WebBaseLoader(\"https://www.example.com\")\n",
    "docs = loader.load()\n",
    "\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ea97ace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pypdf in /Users/apoltavets/anna-apps/ml-and-engineering-docs/.venv/lib/python3.11/site-packages (6.0.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "256df75e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libmagic is unavailable but assists in filetype detection. Please consider installing libmagic for better results.\n",
      "Error loading file dataFolder/dataset/empData.txt\n"
     ]
    },
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt_tab')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n\n  Searched in:\n    - '/Users/apoltavets/nltk_data'\n    - '/Users/apoltavets/anna-apps/ml-and-engineering-docs/.venv/nltk_data'\n    - '/Users/apoltavets/anna-apps/ml-and-engineering-docs/.venv/share/nltk_data'\n    - '/Users/apoltavets/anna-apps/ml-and-engineering-docs/.venv/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mLookupError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_community\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdocument_loaders\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DirectoryLoader\n\u001b[32m      9\u001b[39m loader = DirectoryLoader(\u001b[33m'\u001b[39m\u001b[33mdataFolder/dataset\u001b[39m\u001b[33m'\u001b[39m, glob=\u001b[33m'\u001b[39m\u001b[33m**/*.txt\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m docs = \u001b[43mloader\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m docs\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anna-apps/ml-and-engineering-docs/.venv/lib/python3.11/site-packages/langchain_community/document_loaders/directory.py:117\u001b[39m, in \u001b[36mDirectoryLoader.load\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    115\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> List[Document]:\n\u001b[32m    116\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Load documents.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlazy_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anna-apps/ml-and-engineering-docs/.venv/lib/python3.11/site-packages/langchain_community/document_loaders/directory.py:195\u001b[39m, in \u001b[36mDirectoryLoader.lazy_load\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    193\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    194\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m items:\n\u001b[32m--> \u001b[39m\u001b[32m195\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._lazy_load_file(i, p, pbar)\n\u001b[32m    197\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m pbar:\n\u001b[32m    198\u001b[39m     pbar.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anna-apps/ml-and-engineering-docs/.venv/lib/python3.11/site-packages/langchain_community/document_loaders/directory.py:233\u001b[39m, in \u001b[36mDirectoryLoader._lazy_load_file\u001b[39m\u001b[34m(self, item, path, pbar)\u001b[39m\n\u001b[32m    231\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    232\u001b[39m         logger.error(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mError loading file \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(item)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m233\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m    234\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    235\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m pbar:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anna-apps/ml-and-engineering-docs/.venv/lib/python3.11/site-packages/langchain_community/document_loaders/directory.py:223\u001b[39m, in \u001b[36mDirectoryLoader._lazy_load_file\u001b[39m\u001b[34m(self, item, path, pbar)\u001b[39m\n\u001b[32m    221\u001b[39m loader = \u001b[38;5;28mself\u001b[39m.loader_cls(\u001b[38;5;28mstr\u001b[39m(item), **\u001b[38;5;28mself\u001b[39m.loader_kwargs)\n\u001b[32m    222\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m223\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubdoc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloader\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlazy_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    224\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubdoc\u001b[49m\n\u001b[32m    225\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anna-apps/ml-and-engineering-docs/.venv/lib/python3.11/site-packages/langchain_community/document_loaders/unstructured.py:107\u001b[39m, in \u001b[36mUnstructuredBaseLoader.lazy_load\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    105\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mlazy_load\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> Iterator[Document]:\n\u001b[32m    106\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Load file.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m107\u001b[39m     elements = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_elements\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    108\u001b[39m     \u001b[38;5;28mself\u001b[39m._post_process_elements(elements)\n\u001b[32m    109\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.mode == \u001b[33m\"\u001b[39m\u001b[33melements\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anna-apps/ml-and-engineering-docs/.venv/lib/python3.11/site-packages/langchain_community/document_loaders/unstructured.py:228\u001b[39m, in \u001b[36mUnstructuredFileLoader._get_elements\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    226\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m.file_path, Path):\n\u001b[32m    227\u001b[39m     \u001b[38;5;28mself\u001b[39m.file_path = \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m.file_path)\n\u001b[32m--> \u001b[39m\u001b[32m228\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpartition\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43munstructured_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anna-apps/ml-and-engineering-docs/.venv/lib/python3.11/site-packages/unstructured/partition/auto.py:292\u001b[39m, in \u001b[36mpartition\u001b[39m\u001b[34m(filename, file, encoding, content_type, url, headers, ssl_verify, request_timeout, strategy, skip_infer_table_types, ocr_languages, languages, detect_language_per_element, pdf_infer_table_structure, extract_images_in_pdf, extract_image_block_types, extract_image_block_output_dir, extract_image_block_to_payload, data_source_metadata, metadata_filename, hi_res_model_name, model_name, starting_page_number, **kwargs)\u001b[39m\n\u001b[32m    289\u001b[39m partitioning_kwargs[\u001b[33m\"\u001b[39m\u001b[33mextract_image_block_to_payload\u001b[39m\u001b[33m\"\u001b[39m] = extract_image_block_to_payload\n\u001b[32m    291\u001b[39m partition = partitioner_loader.get(file_type)\n\u001b[32m--> \u001b[39m\u001b[32m292\u001b[39m elements = \u001b[43mpartition\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mpartitioning_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    293\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m augment_metadata(elements)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anna-apps/ml-and-engineering-docs/.venv/lib/python3.11/site-packages/unstructured/partition/common/metadata.py:162\u001b[39m, in \u001b[36mapply_metadata.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    160\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(*args: _P.args, **kwargs: _P.kwargs) -> \u001b[38;5;28mlist\u001b[39m[Element]:\n\u001b[32m--> \u001b[39m\u001b[32m162\u001b[39m     elements = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    163\u001b[39m     call_args = get_call_args_applying_defaults(func, *args, **kwargs)\n\u001b[32m    165\u001b[39m     \u001b[38;5;66;03m# ------------------------------------------------------------------------------------\u001b[39;00m\n\u001b[32m    166\u001b[39m     \u001b[38;5;66;03m# unique-ify elements\u001b[39;00m\n\u001b[32m    167\u001b[39m     \u001b[38;5;66;03m# ------------------------------------------------------------------------------------\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    172\u001b[39m     \u001b[38;5;66;03m# instance).\u001b[39;00m\n\u001b[32m    173\u001b[39m     \u001b[38;5;66;03m# ------------------------------------------------------------------------------------\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anna-apps/ml-and-engineering-docs/.venv/lib/python3.11/site-packages/unstructured/chunking/dispatch.py:74\u001b[39m, in \u001b[36madd_chunking_strategy.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     71\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"The decorated function is replaced with this one.\"\"\"\u001b[39;00m\n\u001b[32m     73\u001b[39m \u001b[38;5;66;03m# -- call the partitioning function to get the elements --\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m74\u001b[39m elements = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     76\u001b[39m \u001b[38;5;66;03m# -- look for a chunking-strategy argument --\u001b[39;00m\n\u001b[32m     77\u001b[39m call_args = get_call_args_applying_defaults(func, *args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anna-apps/ml-and-engineering-docs/.venv/lib/python3.11/site-packages/unstructured/partition/text.py:104\u001b[39m, in \u001b[36mpartition_text\u001b[39m\u001b[34m(filename, file, encoding, text, paragraph_grouper, detection_origin, **kwargs)\u001b[39m\n\u001b[32m    101\u001b[39m ctext = ctext.strip()\n\u001b[32m    103\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ctext \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_empty_bullet(ctext):\n\u001b[32m--> \u001b[39m\u001b[32m104\u001b[39m     element = \u001b[43melement_from_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    105\u001b[39m     element.metadata = copy.deepcopy(metadata)\n\u001b[32m    106\u001b[39m     elements.append(element)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anna-apps/ml-and-engineering-docs/.venv/lib/python3.11/site-packages/unstructured/partition/text.py:149\u001b[39m, in \u001b[36melement_from_text\u001b[39m\u001b[34m(text, coordinates, coordinate_system)\u001b[39m\n\u001b[32m    143\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m is_possible_numbered_list(text):\n\u001b[32m    144\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ListItem(\n\u001b[32m    145\u001b[39m         text=text,\n\u001b[32m    146\u001b[39m         coordinates=coordinates,\n\u001b[32m    147\u001b[39m         coordinate_system=coordinate_system,\n\u001b[32m    148\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m149\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[43mis_possible_narrative_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    150\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m NarrativeText(\n\u001b[32m    151\u001b[39m         text=text,\n\u001b[32m    152\u001b[39m         coordinates=coordinates,\n\u001b[32m    153\u001b[39m         coordinate_system=coordinate_system,\n\u001b[32m    154\u001b[39m     )\n\u001b[32m    155\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m is_possible_title(text):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anna-apps/ml-and-engineering-docs/.venv/lib/python3.11/site-packages/unstructured/partition/text_type.py:74\u001b[39m, in \u001b[36mis_possible_narrative_text\u001b[39m\u001b[34m(text, cap_threshold, non_alpha_threshold, languages, language_checks)\u001b[39m\n\u001b[32m     69\u001b[39m \u001b[38;5;66;03m# NOTE(robinson): it gets read in from the environment as a string so we need to\u001b[39;00m\n\u001b[32m     70\u001b[39m \u001b[38;5;66;03m# cast it to a float\u001b[39;00m\n\u001b[32m     71\u001b[39m cap_threshold = \u001b[38;5;28mfloat\u001b[39m(\n\u001b[32m     72\u001b[39m     os.environ.get(\u001b[33m\"\u001b[39m\u001b[33mUNSTRUCTURED_NARRATIVE_TEXT_CAP_THRESHOLD\u001b[39m\u001b[33m\"\u001b[39m, cap_threshold),\n\u001b[32m     73\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m74\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mexceeds_cap_ratio\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcap_threshold\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m     75\u001b[39m     trace_logger.detail(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNot narrative. Text exceeds cap ratio \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcap_threshold\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mtext\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)  \u001b[38;5;66;03m# type: ignore # noqa: E501\u001b[39;00m\n\u001b[32m     76\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anna-apps/ml-and-engineering-docs/.venv/lib/python3.11/site-packages/unstructured/partition/text_type.py:278\u001b[39m, in \u001b[36mexceeds_cap_ratio\u001b[39m\u001b[34m(text, threshold)\u001b[39m\n\u001b[32m    265\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Checks the title ratio in a section of text. If a sufficient proportion of the words\u001b[39;00m\n\u001b[32m    266\u001b[39m \u001b[33;03mare capitalized, that can be indicated on non-narrative text (i.e. \"1A. Risk Factors\").\u001b[39;00m\n\u001b[32m    267\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    274\u001b[39m \u001b[33;03m    the function returns True\u001b[39;00m\n\u001b[32m    275\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    276\u001b[39m \u001b[38;5;66;03m# NOTE(robinson) - Currently limiting this to only sections of text with one sentence.\u001b[39;00m\n\u001b[32m    277\u001b[39m \u001b[38;5;66;03m# The assumption is that sections with multiple sentences are not titles.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m278\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43msentence_count\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m)\u001b[49m > \u001b[32m1\u001b[39m:\n\u001b[32m    279\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    281\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m text.isupper():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anna-apps/ml-and-engineering-docs/.venv/lib/python3.11/site-packages/unstructured/partition/text_type.py:219\u001b[39m, in \u001b[36msentence_count\u001b[39m\u001b[34m(text, min_length)\u001b[39m\n\u001b[32m    208\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msentence_count\u001b[39m(text: \u001b[38;5;28mstr\u001b[39m, min_length: Optional[\u001b[38;5;28mint\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m) -> \u001b[38;5;28mint\u001b[39m:\n\u001b[32m    209\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Checks the sentence count for a section of text. Titles should not be more than one\u001b[39;00m\n\u001b[32m    210\u001b[39m \u001b[33;03m    sentence.\u001b[39;00m\n\u001b[32m    211\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    217\u001b[39m \u001b[33;03m        The min number of words a section needs to be for it to be considered a sentence.\u001b[39;00m\n\u001b[32m    218\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m219\u001b[39m     sentences = \u001b[43msent_tokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    220\u001b[39m     count = \u001b[32m0\u001b[39m\n\u001b[32m    221\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m sentence \u001b[38;5;129;01min\u001b[39;00m sentences:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anna-apps/ml-and-engineering-docs/.venv/lib/python3.11/site-packages/unstructured/nlp/tokenize.py:53\u001b[39m, in \u001b[36msent_tokenize\u001b[39m\u001b[34m(text)\u001b[39m\n\u001b[32m     50\u001b[39m \u001b[38;5;129m@lru_cache\u001b[39m(maxsize=CACHE_MAX_SIZE)\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msent_tokenize\u001b[39m(text: \u001b[38;5;28mstr\u001b[39m) -> List[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[32m     52\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"A wrapper around the NLTK sentence tokenizer with LRU caching enabled.\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_sent_tokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anna-apps/ml-and-engineering-docs/.venv/lib/python3.11/site-packages/nltk/tokenize/__init__.py:119\u001b[39m, in \u001b[36msent_tokenize\u001b[39m\u001b[34m(text, language)\u001b[39m\n\u001b[32m    109\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msent_tokenize\u001b[39m(text, language=\u001b[33m\"\u001b[39m\u001b[33menglish\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    110\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    111\u001b[39m \u001b[33;03m    Return a sentence-tokenized copy of *text*,\u001b[39;00m\n\u001b[32m    112\u001b[39m \u001b[33;03m    using NLTK's recommended sentence tokenizer\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    117\u001b[39m \u001b[33;03m    :param language: the model name in the Punkt corpus\u001b[39;00m\n\u001b[32m    118\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m119\u001b[39m     tokenizer = \u001b[43m_get_punkt_tokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlanguage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    120\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m tokenizer.tokenize(text)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anna-apps/ml-and-engineering-docs/.venv/lib/python3.11/site-packages/nltk/tokenize/__init__.py:105\u001b[39m, in \u001b[36m_get_punkt_tokenizer\u001b[39m\u001b[34m(language)\u001b[39m\n\u001b[32m     96\u001b[39m \u001b[38;5;129m@functools\u001b[39m.lru_cache\n\u001b[32m     97\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_get_punkt_tokenizer\u001b[39m(language=\u001b[33m\"\u001b[39m\u001b[33menglish\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m     98\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     99\u001b[39m \u001b[33;03m    A constructor for the PunktTokenizer that utilizes\u001b[39;00m\n\u001b[32m    100\u001b[39m \u001b[33;03m    a lru cache for performance.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    103\u001b[39m \u001b[33;03m    :type language: str\u001b[39;00m\n\u001b[32m    104\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m105\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPunktTokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlanguage\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anna-apps/ml-and-engineering-docs/.venv/lib/python3.11/site-packages/nltk/tokenize/punkt.py:1744\u001b[39m, in \u001b[36mPunktTokenizer.__init__\u001b[39m\u001b[34m(self, lang)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, lang=\u001b[33m\"\u001b[39m\u001b[33menglish\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m   1743\u001b[39m     PunktSentenceTokenizer.\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1744\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mload_lang\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlang\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anna-apps/ml-and-engineering-docs/.venv/lib/python3.11/site-packages/nltk/tokenize/punkt.py:1749\u001b[39m, in \u001b[36mPunktTokenizer.load_lang\u001b[39m\u001b[34m(self, lang)\u001b[39m\n\u001b[32m   1746\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload_lang\u001b[39m(\u001b[38;5;28mself\u001b[39m, lang=\u001b[33m\"\u001b[39m\u001b[33menglish\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m   1747\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnltk\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m find\n\u001b[32m-> \u001b[39m\u001b[32m1749\u001b[39m     lang_dir = \u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtokenizers/punkt_tab/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mlang\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m/\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1750\u001b[39m     \u001b[38;5;28mself\u001b[39m._params = load_punkt_params(lang_dir)\n\u001b[32m   1751\u001b[39m     \u001b[38;5;28mself\u001b[39m._lang = lang\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anna-apps/ml-and-engineering-docs/.venv/lib/python3.11/site-packages/nltk/data.py:579\u001b[39m, in \u001b[36mfind\u001b[39m\u001b[34m(resource_name, paths)\u001b[39m\n\u001b[32m    577\u001b[39m sep = \u001b[33m\"\u001b[39m\u001b[33m*\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m70\u001b[39m\n\u001b[32m    578\u001b[39m resource_not_found = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmsg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m579\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m(resource_not_found)\n",
      "\u001b[31mLookupError\u001b[39m: \n**********************************************************************\n  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt_tab')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n\n  Searched in:\n    - '/Users/apoltavets/nltk_data'\n    - '/Users/apoltavets/anna-apps/ml-and-engineering-docs/.venv/nltk_data'\n    - '/Users/apoltavets/anna-apps/ml-and-engineering-docs/.venv/share/nltk_data'\n    - '/Users/apoltavets/anna-apps/ml-and-engineering-docs/.venv/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "# 4. Directory Loaders\n",
    "\n",
    "# Purpose: Load all files from a folder (with options for file types).\n",
    "\n",
    "#pip install unstructured\n",
    "\n",
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "\n",
    "loader = DirectoryLoader('dataFolder/dataset', glob='**/*.txt')\n",
    "docs = loader.load()\n",
    "\n",
    "docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c450d0af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': '50_Startups.csv', 'row': 0}, page_content='R&D Spend: 165349.2\\nAdministration: 136897.8\\nMarketing Spend: 471784.1\\nState: New York\\nProfit: 192261.83'),\n",
       " Document(metadata={'source': '50_Startups.csv', 'row': 1}, page_content='R&D Spend: 162597.7\\nAdministration: 151377.59\\nMarketing Spend: 443898.53\\nState: California\\nProfit: 191792.06'),\n",
       " Document(metadata={'source': '50_Startups.csv', 'row': 2}, page_content='R&D Spend: 153441.51\\nAdministration: 101145.55\\nMarketing Spend: 407934.54\\nState: Florida\\nProfit: 191050.39'),\n",
       " Document(metadata={'source': '50_Startups.csv', 'row': 3}, page_content='R&D Spend: 144372.41\\nAdministration: 118671.85\\nMarketing Spend: 383199.62\\nState: New York\\nProfit: 182901.99'),\n",
       " Document(metadata={'source': '50_Startups.csv', 'row': 4}, page_content='R&D Spend: 142107.34\\nAdministration: 91391.77\\nMarketing Spend: 366168.42\\nState: Florida\\nProfit: 166187.94'),\n",
       " Document(metadata={'source': '50_Startups.csv', 'row': 5}, page_content='R&D Spend: 131876.9\\nAdministration: 99814.71\\nMarketing Spend: 362861.36\\nState: New York\\nProfit: 156991.12'),\n",
       " Document(metadata={'source': '50_Startups.csv', 'row': 6}, page_content='R&D Spend: 134615.46\\nAdministration: 147198.87\\nMarketing Spend: 127716.82\\nState: California\\nProfit: 156122.51'),\n",
       " Document(metadata={'source': '50_Startups.csv', 'row': 7}, page_content='R&D Spend: 130298.13\\nAdministration: 145530.06\\nMarketing Spend: 323876.68\\nState: Florida\\nProfit: 155752.6'),\n",
       " Document(metadata={'source': '50_Startups.csv', 'row': 8}, page_content='R&D Spend: 120542.52\\nAdministration: 148718.95\\nMarketing Spend: 311613.29\\nState: New York\\nProfit: 152211.77'),\n",
       " Document(metadata={'source': '50_Startups.csv', 'row': 9}, page_content='R&D Spend: 123334.88\\nAdministration: 108679.17\\nMarketing Spend: 304981.62\\nState: California\\nProfit: 149759.96'),\n",
       " Document(metadata={'source': '50_Startups.csv', 'row': 10}, page_content='R&D Spend: 101913.08\\nAdministration: 110594.11\\nMarketing Spend: 229160.95\\nState: Florida\\nProfit: 146121.95'),\n",
       " Document(metadata={'source': '50_Startups.csv', 'row': 11}, page_content='R&D Spend: 100671.96\\nAdministration: 91790.61\\nMarketing Spend: 249744.55\\nState: California\\nProfit: 144259.4'),\n",
       " Document(metadata={'source': '50_Startups.csv', 'row': 12}, page_content='R&D Spend: 93863.75\\nAdministration: 127320.38\\nMarketing Spend: 249839.44\\nState: Florida\\nProfit: 141585.52'),\n",
       " Document(metadata={'source': '50_Startups.csv', 'row': 13}, page_content='R&D Spend: 91992.39\\nAdministration: 135495.07\\nMarketing Spend: 252664.93\\nState: California\\nProfit: 134307.35'),\n",
       " Document(metadata={'source': '50_Startups.csv', 'row': 14}, page_content='R&D Spend: 119943.24\\nAdministration: 156547.42\\nMarketing Spend: 256512.92\\nState: Florida\\nProfit: 132602.65'),\n",
       " Document(metadata={'source': '50_Startups.csv', 'row': 15}, page_content='R&D Spend: 114523.61\\nAdministration: 122616.84\\nMarketing Spend: 261776.23\\nState: New York\\nProfit: 129917.04'),\n",
       " Document(metadata={'source': '50_Startups.csv', 'row': 16}, page_content='R&D Spend: 78013.11\\nAdministration: 121597.55\\nMarketing Spend: 264346.06\\nState: California\\nProfit: 126992.93'),\n",
       " Document(metadata={'source': '50_Startups.csv', 'row': 17}, page_content='R&D Spend: 94657.16\\nAdministration: 145077.58\\nMarketing Spend: 282574.31\\nState: New York\\nProfit: 125370.37'),\n",
       " Document(metadata={'source': '50_Startups.csv', 'row': 18}, page_content='R&D Spend: 91749.16\\nAdministration: 114175.79\\nMarketing Spend: 294919.57\\nState: Florida\\nProfit: 124266.9'),\n",
       " Document(metadata={'source': '50_Startups.csv', 'row': 19}, page_content='R&D Spend: 86419.7\\nAdministration: 153514.11\\nMarketing Spend: 0\\nState: New York\\nProfit: 122776.86'),\n",
       " Document(metadata={'source': '50_Startups.csv', 'row': 20}, page_content='R&D Spend: 76253.86\\nAdministration: 113867.3\\nMarketing Spend: 298664.47\\nState: California\\nProfit: 118474.03'),\n",
       " Document(metadata={'source': '50_Startups.csv', 'row': 21}, page_content='R&D Spend: 78389.47\\nAdministration: 153773.43\\nMarketing Spend: 299737.29\\nState: New York\\nProfit: 111313.02'),\n",
       " Document(metadata={'source': '50_Startups.csv', 'row': 22}, page_content='R&D Spend: 73994.56\\nAdministration: 122782.75\\nMarketing Spend: 303319.26\\nState: Florida\\nProfit: 110352.25'),\n",
       " Document(metadata={'source': '50_Startups.csv', 'row': 23}, page_content='R&D Spend: 67532.53\\nAdministration: 105751.03\\nMarketing Spend: 304768.73\\nState: Florida\\nProfit: 108733.99'),\n",
       " Document(metadata={'source': '50_Startups.csv', 'row': 24}, page_content='R&D Spend: 77044.01\\nAdministration: 99281.34\\nMarketing Spend: 140574.81\\nState: New York\\nProfit: 108552.04'),\n",
       " Document(metadata={'source': '50_Startups.csv', 'row': 25}, page_content='R&D Spend: 64664.71\\nAdministration: 139553.16\\nMarketing Spend: 137962.62\\nState: California\\nProfit: 107404.34'),\n",
       " Document(metadata={'source': '50_Startups.csv', 'row': 26}, page_content='R&D Spend: 75328.87\\nAdministration: 144135.98\\nMarketing Spend: 134050.07\\nState: Florida\\nProfit: 105733.54'),\n",
       " Document(metadata={'source': '50_Startups.csv', 'row': 27}, page_content='R&D Spend: 72107.6\\nAdministration: 127864.55\\nMarketing Spend: 353183.81\\nState: New York\\nProfit: 105008.31'),\n",
       " Document(metadata={'source': '50_Startups.csv', 'row': 28}, page_content='R&D Spend: 66051.52\\nAdministration: 182645.56\\nMarketing Spend: 118148.2\\nState: Florida\\nProfit: 103282.38'),\n",
       " Document(metadata={'source': '50_Startups.csv', 'row': 29}, page_content='R&D Spend: 65605.48\\nAdministration: 153032.06\\nMarketing Spend: 107138.38\\nState: New York\\nProfit: 101004.64'),\n",
       " Document(metadata={'source': '50_Startups.csv', 'row': 30}, page_content='R&D Spend: 61994.48\\nAdministration: 115641.28\\nMarketing Spend: 91131.24\\nState: Florida\\nProfit: 99937.59'),\n",
       " Document(metadata={'source': '50_Startups.csv', 'row': 31}, page_content='R&D Spend: 61136.38\\nAdministration: 152701.92\\nMarketing Spend: 88218.23\\nState: New York\\nProfit: 97483.56'),\n",
       " Document(metadata={'source': '50_Startups.csv', 'row': 32}, page_content='R&D Spend: 63408.86\\nAdministration: 129219.61\\nMarketing Spend: 46085.25\\nState: California\\nProfit: 97427.84'),\n",
       " Document(metadata={'source': '50_Startups.csv', 'row': 33}, page_content='R&D Spend: 55493.95\\nAdministration: 103057.49\\nMarketing Spend: 214634.81\\nState: Florida\\nProfit: 96778.92'),\n",
       " Document(metadata={'source': '50_Startups.csv', 'row': 34}, page_content='R&D Spend: 46426.07\\nAdministration: 157693.92\\nMarketing Spend: 210797.67\\nState: California\\nProfit: 96712.8'),\n",
       " Document(metadata={'source': '50_Startups.csv', 'row': 35}, page_content='R&D Spend: 46014.02\\nAdministration: 85047.44\\nMarketing Spend: 205517.64\\nState: New York\\nProfit: 96479.51'),\n",
       " Document(metadata={'source': '50_Startups.csv', 'row': 36}, page_content='R&D Spend: 28663.76\\nAdministration: 127056.21\\nMarketing Spend: 201126.82\\nState: Florida\\nProfit: 90708.19'),\n",
       " Document(metadata={'source': '50_Startups.csv', 'row': 37}, page_content='R&D Spend: 44069.95\\nAdministration: 51283.14\\nMarketing Spend: 197029.42\\nState: California\\nProfit: 89949.14'),\n",
       " Document(metadata={'source': '50_Startups.csv', 'row': 38}, page_content='R&D Spend: 20229.59\\nAdministration: 65947.93\\nMarketing Spend: 185265.1\\nState: New York\\nProfit: 81229.06'),\n",
       " Document(metadata={'source': '50_Startups.csv', 'row': 39}, page_content='R&D Spend: 38558.51\\nAdministration: 82982.09\\nMarketing Spend: 174999.3\\nState: California\\nProfit: 81005.76'),\n",
       " Document(metadata={'source': '50_Startups.csv', 'row': 40}, page_content='R&D Spend: 28754.33\\nAdministration: 118546.05\\nMarketing Spend: 172795.67\\nState: California\\nProfit: 78239.91'),\n",
       " Document(metadata={'source': '50_Startups.csv', 'row': 41}, page_content='R&D Spend: 27892.92\\nAdministration: 84710.77\\nMarketing Spend: 164470.71\\nState: Florida\\nProfit: 77798.83'),\n",
       " Document(metadata={'source': '50_Startups.csv', 'row': 42}, page_content='R&D Spend: 23640.93\\nAdministration: 96189.63\\nMarketing Spend: 148001.11\\nState: California\\nProfit: 71498.49'),\n",
       " Document(metadata={'source': '50_Startups.csv', 'row': 43}, page_content='R&D Spend: 15505.73\\nAdministration: 127382.3\\nMarketing Spend: 35534.17\\nState: New York\\nProfit: 69758.98'),\n",
       " Document(metadata={'source': '50_Startups.csv', 'row': 44}, page_content='R&D Spend: 22177.74\\nAdministration: 154806.14\\nMarketing Spend: 28334.72\\nState: California\\nProfit: 65200.33'),\n",
       " Document(metadata={'source': '50_Startups.csv', 'row': 45}, page_content='R&D Spend: 1000.23\\nAdministration: 124153.04\\nMarketing Spend: 1903.93\\nState: New York\\nProfit: 64926.08'),\n",
       " Document(metadata={'source': '50_Startups.csv', 'row': 46}, page_content='R&D Spend: 1315.46\\nAdministration: 115816.21\\nMarketing Spend: 297114.46\\nState: Florida\\nProfit: 49490.75'),\n",
       " Document(metadata={'source': '50_Startups.csv', 'row': 47}, page_content='R&D Spend: 0\\nAdministration: 135426.92\\nMarketing Spend: 0\\nState: California\\nProfit: 42559.73'),\n",
       " Document(metadata={'source': '50_Startups.csv', 'row': 48}, page_content='R&D Spend: 542.05\\nAdministration: 51743.15\\nMarketing Spend: 0\\nState: New York\\nProfit: 35673.41'),\n",
       " Document(metadata={'source': '50_Startups.csv', 'row': 49}, page_content='R&D Spend: 0\\nAdministration: 116983.8\\nMarketing Spend: 45173.06\\nState: California\\nProfit: 14681.4')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5. CSV & DataFrame Loaders\n",
    "\n",
    "# Purpose: Load data from CSVs, Excel, and other tabular sources.\n",
    "\n",
    "from langchain_community.document_loaders import CSVLoader\n",
    "\n",
    "loader = CSVLoader('dataFolder/50_Startups.csv')\n",
    "docs = loader.load()\n",
    "docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "01173f1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={}, page_content='id: 1\\nname: John Doe\\nage: 30\\ndepartment: Sales')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 7. API & Database Loaders\n",
    "\n",
    "# Purpose: Load data from APIs or databases (SQL, NoSQL).\n",
    "\n",
    "# Popular Classes:\n",
    "\n",
    "# SQLDatabaseLoader (for SQL databases)\n",
    "# Custom API loaders (via HTTP requests)\n",
    "\n",
    "from langchain_community.document_loaders import SQLDatabaseLoader\n",
    "from langchain_community.utilities import SQLDatabase\n",
    "\n",
    "# Create the database connection\n",
    "dbEmployee = SQLDatabase.from_uri(\"sqlite:///dataFolder/test.db\")\n",
    "\n",
    "loader = SQLDatabaseLoader(\n",
    "    db=dbEmployee,\n",
    "    query=\"SELECT * FROM employees\"\n",
    ")\n",
    "docs = loader.load()\n",
    "\n",
    "docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b1d7ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
