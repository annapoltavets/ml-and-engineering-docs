{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "32460138",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "079378d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prompt Templates ---- Structured, Reusable text templates used in LLM apps to STANDARDIZE and FORMAT instructions or Queries you send to an AI model\n",
    "#\n",
    "# Types of Prompt Templates:\n",
    "#===============================\n",
    "# 1. SystemMessagePromptTemplate --- This template is used for generating system messages that provide model CONTEXT or PERSONA \n",
    "# 2. HumanMessagePromptTemplate ---- This template is used for generating human message (representing user input)\n",
    "# 3. AIMEssagePromptTemplate ------- Template for generating AIMessage, representing response from the assistant\n",
    "# 4. PromptTemplate ---------------- Basic Template class for creating prompts with static text and variable placement\n",
    "# 5. ChatPromptTemplate ------------ Template for creating prompts with a sequence of message types in chat format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fa8e4a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#New Style\n",
    "from langchain_core.messages import SystemMessage,HumanMessage\n",
    "from langchain import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "#Temperature\n",
    "#\n",
    "# Temperature decides the following\n",
    "# 0 ----- model will only emit facts\n",
    "# 1 ----- model will be super creative\n",
    "#\n",
    "# 0 --------------------------- 1 (0.1,0.2,0.3,0.4,0.5)\n",
    "#\n",
    "#\n",
    "llm = ChatOpenAI(temperature=1,model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e79384d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. **Definition and Scope**: Artificial Intelligence (AI) refers to the simulation of human intelligence in machines programmed to think and learn like humans. It encompasses various subfields, including machine learning, natural language processing, computer vision, and robotics, enabling machines to perform tasks that typically require human intellect.\n",
      "\n",
      "2. **Applications**: AI has widespread applications across numerous industries, such as healthcare (diagnosing diseases), finance (fraud detection), automotive (self-driving cars), customer service (chatbots), and entertainment (recommendation systems). These applications improve efficiency, enhance decision-making, and personalize user experiences.\n",
      "\n",
      "3. **Ethical and Societal Implications**: The rise of AI raises important ethical considerations, including issues of bias, privacy, job displacement, and accountability. As AI systems become more integrated into society, discussions around responsible AI development, transparency, and regulations are essential to ensure that AI benefits humanity while minimizing potential harms.\n"
     ]
    }
   ],
   "source": [
    "question = HumanMessage(\"Tell me about AI in 3 points\")\n",
    "system = SystemMessage(\"Act as an AI expert. Your answers will be on-point\")\n",
    "\n",
    "messages = [system,question]\n",
    "\n",
    "print(llm.invoke(messages).content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b4d1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#when temperature = 0\n",
    "# 1. **Machine Learning and Deep Learning**: AI primarily relies on machine learning (ML) and deep learning (DL) techniques, which enable systems to learn from data and improve their performance over time. ML algorithms identify patterns in data, while DL, a subset of ML, uses neural networks to process complex data structures, such as images and natural language.\n",
    "\n",
    "# 2. **Applications Across Industries**: AI is transforming various sectors, including healthcare (diagnosis and personalized medicine), finance (fraud detection and algorithmic trading), transportation (autonomous vehicles), and customer service (chatbots and virtual assistants). These applications enhance efficiency, reduce costs, and improve decision-making.\n",
    "\n",
    "# 3. **Ethical Considerations and Challenges**: The rapid advancement of AI raises important ethical issues, such as bias in algorithms, data privacy, and the potential for job displacement. Addressing these challenges is crucial for ensuring that AI technologies are developed and deployed responsibly, promoting fairness and transparency in their use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ae6b3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import SystemMessagePromptTemplate,HumanMessagePromptTemplate,PromptTemplate,ChatMessagePromptTemplate, ChatPromptTemplate\n",
    "\n",
    "system = SystemMessagePromptTemplate.from_template(\"Act as a {persona} professor. You answer in short sentences\")\n",
    "\n",
    "question = HumanMessagePromptTemplate.from_template(\"Tell me about {topics} in {points} points\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1a6e4af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['persona'], input_types={}, partial_variables={}, template='Act as a {persona} professor. You answer in short sentences'), additional_kwargs={})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "724f8c3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['points', 'topics'], input_types={}, partial_variables={}, template='Tell me about {topics} in {points} points'), additional_kwargs={})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72a79233",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SystemMessage(content='Act as a AI professor. You answer in short sentences', additional_kwargs={}, response_metadata={})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system.format(persona=\"AI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "961c4a4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HumanMessage(content='Tell me about Langchain in 3 points', additional_kwargs={}, response_metadata={})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question.format(topics=\"Langchain\", points=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "84326bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [system,question]\n",
    "\n",
    "template = ChatPromptTemplate(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3a3f895a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='Act as a gemologist professor. You answer in short sentences', additional_kwargs={}, response_metadata={}), HumanMessage(content='Tell me about Types of Stones in 2 points', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = template.invoke({\n",
    "    'persona':'gemologist',\n",
    "    'topics' :'Types of Stones',\n",
    "    'points' : 2\n",
    "})\n",
    "\n",
    "question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4f597d4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='1. **Precious Stones**: These are rare and valuable, including diamonds, sapphires, rubies, and emeralds. They are prized for their beauty and durability.\\n\\n2. **Semi-Precious Stones**: These are more abundant and include amethyst, turquoise, and garnet. They are often used in jewelry and are generally less expensive than precious stones.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 77, 'prompt_tokens': 33, 'total_tokens': 110, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_e665f7564b', 'id': 'chatcmpl-CCGD0GEEEBTahiea1KzvDpH8SomR8', 'finish_reason': 'stop', 'logprobs': None}, id='run-045e2e8d-8275-4445-aea3-6160acdb2d08-0', usage_metadata={'input_tokens': 33, 'output_tokens': 77, 'total_tokens': 110, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0c6cb95a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'template' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m topics = \u001b[38;5;28minput\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mEnter topic to discuss: \u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      3\u001b[39m points = \u001b[38;5;28minput\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mEnter number of points: \u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m question = \u001b[43mtemplate\u001b[49m.invoke({\n\u001b[32m      6\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mpersona\u001b[39m\u001b[33m'\u001b[39m:persona,\n\u001b[32m      7\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mtopics\u001b[39m\u001b[33m'\u001b[39m :topics,\n\u001b[32m      8\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mpoints\u001b[39m\u001b[33m'\u001b[39m : points\n\u001b[32m      9\u001b[39m })\n\u001b[32m     11\u001b[39m \u001b[38;5;28mprint\u001b[39m(llm.invoke(question).content)\n",
      "\u001b[31mNameError\u001b[39m: name 'template' is not defined"
     ]
    }
   ],
   "source": [
    "persona = input(\"Enter expected persona: \")\n",
    "topics = input(\"Enter topic to discuss: \")\n",
    "points = input(\"Enter number of points: \")\n",
    "\n",
    "question = template.invoke({\n",
    "    'persona':persona,\n",
    "    'topics' :topics,\n",
    "    'points' : points\n",
    "})\n",
    "\n",
    "print(llm.invoke(question).content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca53ec63",
   "metadata": {},
   "source": [
    "# Prompt Template Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "658aee14",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPLATE = \"\"\"\n",
    "You are a helpful assistant that translates the {inputLanguage} to {outputLanguage}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1ebd8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts.prompt import PromptTemplate\n",
    "promptTemplate = PromptTemplate.from_template(\n",
    "    template=TEMPLATE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91741ab1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nYou are a helpful assistant that translates the english to hindi\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "promptTemplate.format(inputLanguage=\"english\", outputLanguage=\"hindi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0b6e9228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Soy Anna Poltavets.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import SystemMessage,HumanMessage\n",
    "from langchain import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "personaForLLM = promptTemplate.invoke({\n",
    "    'inputLanguage': \"english\",\n",
    "    'outputLanguage': \"spanish\"\n",
    "})\n",
    "\n",
    "userMessage = \"I am Anna Poltavets\"\n",
    "messages1 = [SystemMessage(personaForLLM.text),HumanMessage(userMessage)]\n",
    "print(llm.invoke(messages1).content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6023f6a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nYou are a helpful assistant that translates the english to spanish\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "personaForLLM.text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd077ace",
   "metadata": {},
   "source": [
    "# Serializing Prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7588d799",
   "metadata": {},
   "source": [
    "### Store prompts in a physical file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "16e5c8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(input_variables=[\"input\"] , template=\"Tell me a joke in {input} language\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f9207b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt.save(\"prompt.yaml\")\n",
    "prompt.save(\"prompt.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "41f25fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load prompt from file\n",
    "\n",
    "from langchain.prompts import load_prompt\n",
    "promptNew = load_prompt(\"prompt.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9f27341f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tell me a joke in hindi language'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "promptNew.format(input=\"hindi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db659fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
